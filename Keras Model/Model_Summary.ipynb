{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D, MaxPool1D, Flatten\n",
    "from keras.layers import Dropout, Dense, TimeDistributed,LeakyReLU,LSTM,TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_Oct_w2.csv')\n",
    "df = df.replace('-',np.nan)\n",
    "df = df.fillna(0)\n",
    "X = df.drop(['REGISTRATION_DATE','RETAILER_NUMBER','MSISDN','FAKE'],axis=1)\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "X = X.values\n",
    "Y = df['FAKE']\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42,stratify=Y)\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X.shape[1],1)\n",
    "X = X.reshape(X.shape[0],X.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 128)           66560     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 64)            8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 50, 32)            2080      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 50, 16)            528       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 50, 8)             136       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 209,545\n",
      "Trainable params: 209,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 651134 samples, validate on 162784 samples\n",
      "Epoch 1/10\n",
      "651134/651134 [==============================] - 1680s 3ms/step - loss: 0.4597 - acc: 0.8066 - val_loss: 0.4588 - val_acc: 0.8065\n",
      "Epoch 2/10\n",
      "651134/651134 [==============================] - 1662s 3ms/step - loss: 0.4591 - acc: 0.8067 - val_loss: 0.4587 - val_acc: 0.8069\n",
      "Epoch 3/10\n",
      "651134/651134 [==============================] - 1627s 2ms/step - loss: 0.4587 - acc: 0.8067 - val_loss: 0.4582 - val_acc: 0.8067\n",
      "Epoch 4/10\n",
      "651134/651134 [==============================] - 1610s 2ms/step - loss: 0.4585 - acc: 0.8067 - val_loss: 0.4587 - val_acc: 0.8062\n",
      "Epoch 5/10\n",
      "651134/651134 [==============================] - 1611s 2ms/step - loss: 0.4580 - acc: 0.8069 - val_loss: 0.4573 - val_acc: 0.8068\n",
      "Epoch 6/10\n",
      "651134/651134 [==============================] - 1649s 3ms/step - loss: 0.4575 - acc: 0.8071 - val_loss: 0.4578 - val_acc: 0.8069\n",
      "Epoch 7/10\n",
      "651134/651134 [==============================] - 1673s 3ms/step - loss: 0.4572 - acc: 0.8071 - val_loss: 0.4571 - val_acc: 0.8068\n",
      "Epoch 8/10\n",
      "651134/651134 [==============================] - 1680s 3ms/step - loss: 0.4569 - acc: 0.8072 - val_loss: 0.4566 - val_acc: 0.8070\n",
      "Epoch 9/10\n",
      "651134/651134 [==============================] - 1774s 3ms/step - loss: 0.4567 - acc: 0.8072 - val_loss: 0.4580 - val_acc: 0.8067\n",
      "Epoch 10/10\n",
      "651134/651134 [==============================] - 7000s 11ms/step - loss: 0.4564 - acc: 0.8073 - val_loss: 0.4577 - val_acc: 0.8068\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(16, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(8, activation='relu')))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.load_weights('Trail_weights.h5')\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "history = model.fit(X_train,y_train, epochs=10, shuffle=True,validation_data=(X_test,y_test))\n",
    "model.save('Lstm_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 50, 64)            24640     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 50, 32)            6176      \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 50, 16)            1552      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 25, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                12832     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 47,889\n",
      "Trainable params: 47,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 838860 samples, validate on 209715 samples\n",
      "Epoch 1/12\n",
      "838860/838860 [==============================] - 515s 614us/step - loss: 0.6020 - acc: 0.6579 - val_loss: 0.5803 - val_acc: 0.6760\n",
      "Epoch 2/12\n",
      "838860/838860 [==============================] - 503s 600us/step - loss: 0.5858 - acc: 0.6718 - val_loss: 0.5792 - val_acc: 0.6766\n",
      "Epoch 3/12\n",
      "838860/838860 [==============================] - 917s 1ms/step - loss: 0.5842 - acc: 0.6727 - val_loss: 0.5794 - val_acc: 0.6768\n",
      "Epoch 4/12\n",
      "838860/838860 [==============================] - 3873s 5ms/step - loss: 0.5830 - acc: 0.6739 - val_loss: 0.5793 - val_acc: 0.6773\n",
      "Epoch 5/12\n",
      "838860/838860 [==============================] - 472s 562us/step - loss: 0.5824 - acc: 0.6743 - val_loss: 0.5784 - val_acc: 0.6780\n",
      "Epoch 6/12\n",
      "838860/838860 [==============================] - 498s 594us/step - loss: 0.5819 - acc: 0.6750 - val_loss: 0.5777 - val_acc: 0.6772\n",
      "Epoch 7/12\n",
      "838860/838860 [==============================] - 524s 624us/step - loss: 0.5814 - acc: 0.6750 - val_loss: 0.5776 - val_acc: 0.6773\n",
      "Epoch 8/12\n",
      "838860/838860 [==============================] - 522s 622us/step - loss: 0.5812 - acc: 0.6751 - val_loss: 0.5774 - val_acc: 0.6779\n",
      "Epoch 9/12\n",
      "838860/838860 [==============================] - 359s 428us/step - loss: 0.5809 - acc: 0.6754 - val_loss: 0.5775 - val_acc: 0.6786\n",
      "Epoch 10/12\n",
      "838860/838860 [==============================] - 290s 346us/step - loss: 0.5806 - acc: 0.6759 - val_loss: 0.5776 - val_acc: 0.6778\n",
      "Epoch 11/12\n",
      "838860/838860 [==============================] - 290s 345us/step - loss: 0.5806 - acc: 0.6753 - val_loss: 0.5781 - val_acc: 0.6775\n",
      "Epoch 12/12\n",
      "838860/838860 [==============================] - 286s 341us/step - loss: 0.5801 - acc: 0.6763 - val_loss: 0.5768 - val_acc: 0.6786\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(128, 3, padding='same', input_shape=input_shape))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv1D(64, 3, activation='relu',padding='same'))\n",
    "model.add(Conv1D(32, 3, activation='relu',padding='same'))\n",
    "model.add(Conv1D(16, 3, activation='relu',padding='same'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer='SGD',metrics=['acc'])\n",
    "history = model.fit(X_train,y_train, epochs=12, shuffle=True,validation_data=(X_test,y_test))\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('updated_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7f539fdf9cbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209715/209715 [==============================] - 98s 467us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "\n",
    "y_pred_bool = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] > 0.50:\n",
    "        y_pred_bool.append(1)\n",
    "    else:\n",
    "        y_pred_bool.append(0) \n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred_bool,output_dict=True)\n",
    "df1 = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.725886</td>\n",
       "      <td>0.692288</td>\n",
       "      <td>104599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698072</td>\n",
       "      <td>0.630646</td>\n",
       "      <td>0.662648</td>\n",
       "      <td>105116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.678149</td>\n",
       "      <td>0.678149</td>\n",
       "      <td>0.678149</td>\n",
       "      <td>0.678149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.679867</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.677468</td>\n",
       "      <td>209715.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.679912</td>\n",
       "      <td>0.678149</td>\n",
       "      <td>0.677431</td>\n",
       "      <td>209715.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support\n",
       "0              0.661662  0.725886  0.692288  104599.000000\n",
       "1              0.698072  0.630646  0.662648  105116.000000\n",
       "accuracy       0.678149  0.678149  0.678149       0.678149\n",
       "macro avg      0.679867  0.678266  0.677468  209715.000000\n",
       "weighted avg   0.679912  0.678149  0.677431  209715.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 838860 samples, validate on 209715 samples\n",
      "Epoch 1/40\n",
      "838860/838860 [==============================] - 87s 104us/step - loss: 0.5964 - accuracy: 0.6657 - val_loss: 0.5831 - val_accuracy: 0.6740\n",
      "Epoch 2/40\n",
      "838860/838860 [==============================] - 94s 112us/step - loss: 0.5915 - accuracy: 0.6710 - val_loss: 0.5809 - val_accuracy: 0.6746\n",
      "Epoch 3/40\n",
      "838860/838860 [==============================] - 97s 115us/step - loss: 0.5904 - accuracy: 0.6721 - val_loss: 0.5809 - val_accuracy: 0.6761\n",
      "Epoch 4/40\n",
      "838860/838860 [==============================] - 99s 118us/step - loss: 0.5905 - accuracy: 0.6727 - val_loss: 0.5819 - val_accuracy: 0.6760\n",
      "Epoch 5/40\n",
      "838860/838860 [==============================] - 96s 114us/step - loss: 0.5903 - accuracy: 0.6725 - val_loss: 0.5802 - val_accuracy: 0.6768\n",
      "Epoch 6/40\n",
      "838860/838860 [==============================] - 95s 113us/step - loss: 0.5902 - accuracy: 0.6731 - val_loss: 0.5806 - val_accuracy: 0.6762\n",
      "Epoch 7/40\n",
      "838860/838860 [==============================] - 94s 112us/step - loss: 0.5898 - accuracy: 0.6727 - val_loss: 0.5798 - val_accuracy: 0.6768\n",
      "Epoch 8/40\n",
      "838860/838860 [==============================] - 95s 113us/step - loss: 0.5898 - accuracy: 0.6731 - val_loss: 0.5802 - val_accuracy: 0.6762\n",
      "Epoch 9/40\n",
      "838860/838860 [==============================] - 94s 112us/step - loss: 0.5901 - accuracy: 0.6727 - val_loss: 0.5804 - val_accuracy: 0.6757\n",
      "Epoch 10/40\n",
      "838860/838860 [==============================] - 96s 114us/step - loss: 0.5897 - accuracy: 0.6728 - val_loss: 0.5804 - val_accuracy: 0.6765\n",
      "Epoch 11/40\n",
      "838860/838860 [==============================] - 95s 113us/step - loss: 0.5897 - accuracy: 0.6732 - val_loss: 0.5803 - val_accuracy: 0.6771\n",
      "Epoch 12/40\n",
      "838860/838860 [==============================] - 97s 115us/step - loss: 0.5899 - accuracy: 0.6733 - val_loss: 0.5827 - val_accuracy: 0.6766\n",
      "Epoch 13/40\n",
      "838860/838860 [==============================] - 94s 112us/step - loss: 0.5901 - accuracy: 0.6725 - val_loss: 0.5795 - val_accuracy: 0.6772\n",
      "Epoch 14/40\n",
      "838860/838860 [==============================] - 95s 114us/step - loss: 0.5898 - accuracy: 0.6734 - val_loss: 0.5821 - val_accuracy: 0.6769\n",
      "Epoch 15/40\n",
      "838860/838860 [==============================] - 96s 115us/step - loss: 0.5900 - accuracy: 0.6726 - val_loss: 0.5804 - val_accuracy: 0.6774\n",
      "Epoch 16/40\n",
      "838860/838860 [==============================] - 90s 107us/step - loss: 0.5896 - accuracy: 0.6726 - val_loss: 0.5804 - val_accuracy: 0.6756\n",
      "Epoch 17/40\n",
      "838860/838860 [==============================] - 95s 114us/step - loss: 0.5900 - accuracy: 0.6729 - val_loss: 0.5801 - val_accuracy: 0.6771\n",
      "Epoch 18/40\n",
      "838860/838860 [==============================] - 91s 109us/step - loss: 0.5898 - accuracy: 0.6729 - val_loss: 0.5805 - val_accuracy: 0.6767\n",
      "Epoch 19/40\n",
      "838860/838860 [==============================] - 89s 106us/step - loss: 0.5899 - accuracy: 0.6731 - val_loss: 0.5794 - val_accuracy: 0.6773\n",
      "Epoch 20/40\n",
      "838860/838860 [==============================] - 92s 110us/step - loss: 0.5898 - accuracy: 0.6732 - val_loss: 0.5813 - val_accuracy: 0.6766\n",
      "Epoch 21/40\n",
      "838860/838860 [==============================] - 88s 105us/step - loss: 0.5898 - accuracy: 0.6726 - val_loss: 0.5797 - val_accuracy: 0.6766\n",
      "Epoch 22/40\n",
      "838860/838860 [==============================] - 95s 113us/step - loss: 0.5899 - accuracy: 0.6731 - val_loss: 0.5795 - val_accuracy: 0.6755\n",
      "Epoch 23/40\n",
      "838860/838860 [==============================] - 99s 118us/step - loss: 0.5897 - accuracy: 0.6732 - val_loss: 0.5809 - val_accuracy: 0.6774\n",
      "Epoch 24/40\n",
      "838860/838860 [==============================] - 96s 114us/step - loss: 0.5898 - accuracy: 0.6729 - val_loss: 0.5798 - val_accuracy: 0.6769\n",
      "Epoch 25/40\n",
      "838860/838860 [==============================] - 88s 105us/step - loss: 0.5900 - accuracy: 0.6729 - val_loss: 0.5805 - val_accuracy: 0.6760\n",
      "Epoch 26/40\n",
      "838860/838860 [==============================] - 92s 110us/step - loss: 0.5899 - accuracy: 0.6731 - val_loss: 0.5790 - val_accuracy: 0.6772\n",
      "Epoch 27/40\n",
      "838860/838860 [==============================] - 92s 110us/step - loss: 0.5899 - accuracy: 0.6732 - val_loss: 0.5794 - val_accuracy: 0.6769\n",
      "Epoch 28/40\n",
      "838860/838860 [==============================] - 95s 113us/step - loss: 0.5900 - accuracy: 0.6731 - val_loss: 0.5795 - val_accuracy: 0.6762\n",
      "Epoch 29/40\n",
      "838860/838860 [==============================] - 95s 113us/step - loss: 0.5900 - accuracy: 0.6730 - val_loss: 0.5802 - val_accuracy: 0.6768\n",
      "Epoch 30/40\n",
      "838860/838860 [==============================] - 94s 112us/step - loss: 0.5900 - accuracy: 0.6729 - val_loss: 0.5811 - val_accuracy: 0.6755\n",
      "Epoch 31/40\n",
      "838860/838860 [==============================] - 95s 114us/step - loss: 0.5897 - accuracy: 0.6729 - val_loss: 0.5810 - val_accuracy: 0.6766\n",
      "Epoch 32/40\n",
      "838860/838860 [==============================] - 86s 103us/step - loss: 0.5898 - accuracy: 0.6732 - val_loss: 0.5802 - val_accuracy: 0.6770\n",
      "Epoch 33/40\n",
      "838860/838860 [==============================] - 87s 104us/step - loss: 0.5899 - accuracy: 0.6725 - val_loss: 0.5794 - val_accuracy: 0.6775\n",
      "Epoch 34/40\n",
      "838860/838860 [==============================] - 88s 104us/step - loss: 0.5897 - accuracy: 0.6727 - val_loss: 0.5798 - val_accuracy: 0.6774\n",
      "Epoch 35/40\n",
      "838860/838860 [==============================] - 92s 109us/step - loss: 0.5899 - accuracy: 0.6727 - val_loss: 0.5804 - val_accuracy: 0.6770\n",
      "Epoch 36/40\n",
      "838860/838860 [==============================] - 94s 112us/step - loss: 0.5900 - accuracy: 0.6726 - val_loss: 0.5803 - val_accuracy: 0.6765\n",
      "Epoch 37/40\n",
      "838860/838860 [==============================] - 88s 105us/step - loss: 0.5899 - accuracy: 0.6727 - val_loss: 0.5796 - val_accuracy: 0.6773\n",
      "Epoch 38/40\n",
      "838860/838860 [==============================] - 85s 101us/step - loss: 0.5897 - accuracy: 0.6731 - val_loss: 0.5814 - val_accuracy: 0.6768\n",
      "Epoch 39/40\n",
      "838860/838860 [==============================] - 84s 100us/step - loss: 0.5897 - accuracy: 0.6728 - val_loss: 0.5805 - val_accuracy: 0.6774\n",
      "Epoch 40/40\n",
      "220180/838860 [======>.......................] - ETA: 55s - loss: 0.5886 - accuracy: 0.6745"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=X_train.shape[1], activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(8, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251187/251187 [==============================] - 162s 645us/step\n"
     ]
    }
   ],
   "source": [
    "# X = X.reshape(X.shape[0],X.shape[1],1)\n",
    "y_pred = model.predict(X, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort = df.sort_values(by=['pred'])\n",
    "\n",
    "df_sort['ind'] = [x for x in range(df_sort.shape[0])]\n",
    "\n",
    "\n",
    "df_sort['bucket_no'] = round(   ((df_sort['ind']+1)/df_sort.shape[0]) * 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket_no\n",
      "0.0     0.000486\n",
      "1.0     0.067426\n",
      "2.0     0.102549\n",
      "3.0     0.135341\n",
      "4.0     0.171577\n",
      "5.0     0.211526\n",
      "6.0     0.254185\n",
      "7.0     0.307529\n",
      "8.0     0.380508\n",
      "9.0     0.474685\n",
      "10.0    0.600819\n",
      "Name: pred, dtype: float32 bucket_no\n",
      "0.0     0.067426\n",
      "1.0     0.102547\n",
      "2.0     0.135340\n",
      "3.0     0.171576\n",
      "4.0     0.211524\n",
      "5.0     0.254184\n",
      "6.0     0.307527\n",
      "7.0     0.380506\n",
      "8.0     0.474683\n",
      "9.0     0.600806\n",
      "10.0    0.972367\n",
      "Name: pred, dtype: float32 bucket_no\n",
      "0.0     12559\n",
      "1.0     25119\n",
      "2.0     25118\n",
      "3.0     25119\n",
      "4.0     25119\n",
      "5.0     25118\n",
      "6.0     25119\n",
      "7.0     25119\n",
      "8.0     25118\n",
      "9.0     25119\n",
      "10.0    12560\n",
      "Name: RETAILER_NUMBER, dtype: int64 bucket_no\n",
      "0.0       417\n",
      "1.0      1535\n",
      "2.0      2301\n",
      "3.0      3197\n",
      "4.0      4204\n",
      "5.0      5427\n",
      "6.0      6670\n",
      "7.0      8451\n",
      "8.0     10502\n",
      "9.0     13455\n",
      "10.0     9206\n",
      "Name: RETAILER_NUMBER, dtype: int64 bucket_no\n",
      "0.0     0.033203\n",
      "1.0     0.061109\n",
      "2.0     0.091608\n",
      "3.0     0.127274\n",
      "4.0     0.167363\n",
      "5.0     0.216060\n",
      "6.0     0.265536\n",
      "7.0     0.336439\n",
      "8.0     0.418107\n",
      "9.0     0.535650\n",
      "10.0    0.732962\n",
      "Name: RETAILER_NUMBER, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_sort.groupby(['bucket_no']).min()['pred'], df_sort.groupby(['bucket_no']).max()['pred'], df_sort.groupby(['bucket_no']).count()['RETAILER_NUMBER'], df_sort[df_sort['FAKE'] == 1].groupby(['bucket_no']).count()['RETAILER_NUMBER'], df_sort[df_sort['FAKE'] == 1].groupby(['bucket_no']).count()['RETAILER_NUMBER']/df_sort.groupby(['bucket_no']).count()['RETAILER_NUMBER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_sort.groupby(['bucket_no']).min()['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.Series(df1,name='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_sort.groupby(['bucket_no']).max()['pred']\n",
    "df2 = pd.Series(df2,name='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_sort.groupby(['bucket_no']).count()['RETAILER_NUMBER']\n",
    "df3 = pd.Series(df3,name='Total')\n",
    "df4 = df_sort[df_sort['FAKE'] == 1].groupby(['bucket_no']).count()['RETAILER_NUMBER']\n",
    "df4 = pd.Series(df4,name = 'Fakes')\n",
    "df5 = df_sort[df_sort['FAKE'] == 1].groupby(['bucket_no']).count()['RETAILER_NUMBER']/df_sort.groupby(['bucket_no']).count()['RETAILER_NUMBER']\n",
    "df5 = pd.Series(df5,name='Pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df1,df2,df3,df4,df5],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>Total</th>\n",
       "      <th>Fakes</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>12559</td>\n",
       "      <td>417</td>\n",
       "      <td>0.033203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.067426</td>\n",
       "      <td>0.102547</td>\n",
       "      <td>25119</td>\n",
       "      <td>1535</td>\n",
       "      <td>0.061109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.102549</td>\n",
       "      <td>0.135340</td>\n",
       "      <td>25118</td>\n",
       "      <td>2301</td>\n",
       "      <td>0.091608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.135341</td>\n",
       "      <td>0.171576</td>\n",
       "      <td>25119</td>\n",
       "      <td>3197</td>\n",
       "      <td>0.127274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.171577</td>\n",
       "      <td>0.211524</td>\n",
       "      <td>25119</td>\n",
       "      <td>4204</td>\n",
       "      <td>0.167363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.211526</td>\n",
       "      <td>0.254184</td>\n",
       "      <td>25118</td>\n",
       "      <td>5427</td>\n",
       "      <td>0.216060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.254185</td>\n",
       "      <td>0.307527</td>\n",
       "      <td>25119</td>\n",
       "      <td>6670</td>\n",
       "      <td>0.265536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.307529</td>\n",
       "      <td>0.380506</td>\n",
       "      <td>25119</td>\n",
       "      <td>8451</td>\n",
       "      <td>0.336439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.380508</td>\n",
       "      <td>0.474683</td>\n",
       "      <td>25118</td>\n",
       "      <td>10502</td>\n",
       "      <td>0.418107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.474685</td>\n",
       "      <td>0.600806</td>\n",
       "      <td>25119</td>\n",
       "      <td>13455</td>\n",
       "      <td>0.535650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.600819</td>\n",
       "      <td>0.972367</td>\n",
       "      <td>12560</td>\n",
       "      <td>9206</td>\n",
       "      <td>0.732962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                min       max  Total  Fakes      Pred\n",
       "bucket_no                                            \n",
       "0.0        0.000486  0.067426  12559    417  0.033203\n",
       "1.0        0.067426  0.102547  25119   1535  0.061109\n",
       "2.0        0.102549  0.135340  25118   2301  0.091608\n",
       "3.0        0.135341  0.171576  25119   3197  0.127274\n",
       "4.0        0.171577  0.211524  25119   4204  0.167363\n",
       "5.0        0.211526  0.254184  25118   5427  0.216060\n",
       "6.0        0.254185  0.307527  25119   6670  0.265536\n",
       "7.0        0.307529  0.380506  25119   8451  0.336439\n",
       "8.0        0.380508  0.474683  25118  10502  0.418107\n",
       "9.0        0.474685  0.600806  25119  13455  0.535650\n",
       "10.0       0.600819  0.972367  12560   9206  0.732962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = df_final['Fakes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ele for ele in reversed(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9206, 13455, 10502, 8451, 6670, 5427, 4204, 3197, 2301, 1535, 417]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    if i !=0:\n",
    "        a[i] = a[i]+ a[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9206, 22661, 33163, 41614, 48284, 53711, 57915, 61112, 63413, 64948, 65365]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ele for ele in reversed(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65365, 64948, 63413, 61112, 57915, 53711, 48284, 41614, 33163, 22661, 9206]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.Series(a,name='fake_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df1,df2,df3,df4,df5,df6],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>Total</th>\n",
       "      <th>Fakes</th>\n",
       "      <th>Pred</th>\n",
       "      <th>fake_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>12559</td>\n",
       "      <td>417</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>65365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.067426</td>\n",
       "      <td>0.102547</td>\n",
       "      <td>25119</td>\n",
       "      <td>1535</td>\n",
       "      <td>0.061109</td>\n",
       "      <td>64948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.102549</td>\n",
       "      <td>0.135340</td>\n",
       "      <td>25118</td>\n",
       "      <td>2301</td>\n",
       "      <td>0.091608</td>\n",
       "      <td>63413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.135341</td>\n",
       "      <td>0.171576</td>\n",
       "      <td>25119</td>\n",
       "      <td>3197</td>\n",
       "      <td>0.127274</td>\n",
       "      <td>61112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.171577</td>\n",
       "      <td>0.211524</td>\n",
       "      <td>25119</td>\n",
       "      <td>4204</td>\n",
       "      <td>0.167363</td>\n",
       "      <td>57915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.211526</td>\n",
       "      <td>0.254184</td>\n",
       "      <td>25118</td>\n",
       "      <td>5427</td>\n",
       "      <td>0.216060</td>\n",
       "      <td>53711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.254185</td>\n",
       "      <td>0.307527</td>\n",
       "      <td>25119</td>\n",
       "      <td>6670</td>\n",
       "      <td>0.265536</td>\n",
       "      <td>48284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.307529</td>\n",
       "      <td>0.380506</td>\n",
       "      <td>25119</td>\n",
       "      <td>8451</td>\n",
       "      <td>0.336439</td>\n",
       "      <td>41614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.380508</td>\n",
       "      <td>0.474683</td>\n",
       "      <td>25118</td>\n",
       "      <td>10502</td>\n",
       "      <td>0.418107</td>\n",
       "      <td>33163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.474685</td>\n",
       "      <td>0.600806</td>\n",
       "      <td>25119</td>\n",
       "      <td>13455</td>\n",
       "      <td>0.535650</td>\n",
       "      <td>22661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.600819</td>\n",
       "      <td>0.972367</td>\n",
       "      <td>12560</td>\n",
       "      <td>9206</td>\n",
       "      <td>0.732962</td>\n",
       "      <td>9206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           min       max  Total  Fakes      Pred  fake_count\n",
       "0.0   0.000486  0.067426  12559    417  0.033203       65365\n",
       "1.0   0.067426  0.102547  25119   1535  0.061109       64948\n",
       "2.0   0.102549  0.135340  25118   2301  0.091608       63413\n",
       "3.0   0.135341  0.171576  25119   3197  0.127274       61112\n",
       "4.0   0.171577  0.211524  25119   4204  0.167363       57915\n",
       "5.0   0.211526  0.254184  25118   5427  0.216060       53711\n",
       "6.0   0.254185  0.307527  25119   6670  0.265536       48284\n",
       "7.0   0.307529  0.380506  25119   8451  0.336439       41614\n",
       "8.0   0.380508  0.474683  25118  10502  0.418107       33163\n",
       "9.0   0.474685  0.600806  25119  13455  0.535650       22661\n",
       "10.0  0.600819  0.972367  12560   9206  0.732962        9206"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['recall'] = df_final['fake_count']/df_final['Fakes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>Total</th>\n",
       "      <th>Fakes</th>\n",
       "      <th>Pred</th>\n",
       "      <th>fake_count</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>12559</td>\n",
       "      <td>417</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>65365</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.067426</td>\n",
       "      <td>0.102547</td>\n",
       "      <td>25119</td>\n",
       "      <td>1535</td>\n",
       "      <td>0.061109</td>\n",
       "      <td>64948</td>\n",
       "      <td>0.993620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.102549</td>\n",
       "      <td>0.135340</td>\n",
       "      <td>25118</td>\n",
       "      <td>2301</td>\n",
       "      <td>0.091608</td>\n",
       "      <td>63413</td>\n",
       "      <td>0.970137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.135341</td>\n",
       "      <td>0.171576</td>\n",
       "      <td>25119</td>\n",
       "      <td>3197</td>\n",
       "      <td>0.127274</td>\n",
       "      <td>61112</td>\n",
       "      <td>0.934935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.171577</td>\n",
       "      <td>0.211524</td>\n",
       "      <td>25119</td>\n",
       "      <td>4204</td>\n",
       "      <td>0.167363</td>\n",
       "      <td>57915</td>\n",
       "      <td>0.886025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.211526</td>\n",
       "      <td>0.254184</td>\n",
       "      <td>25118</td>\n",
       "      <td>5427</td>\n",
       "      <td>0.216060</td>\n",
       "      <td>53711</td>\n",
       "      <td>0.821709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.254185</td>\n",
       "      <td>0.307527</td>\n",
       "      <td>25119</td>\n",
       "      <td>6670</td>\n",
       "      <td>0.265536</td>\n",
       "      <td>48284</td>\n",
       "      <td>0.738683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.307529</td>\n",
       "      <td>0.380506</td>\n",
       "      <td>25119</td>\n",
       "      <td>8451</td>\n",
       "      <td>0.336439</td>\n",
       "      <td>41614</td>\n",
       "      <td>0.636640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.380508</td>\n",
       "      <td>0.474683</td>\n",
       "      <td>25118</td>\n",
       "      <td>10502</td>\n",
       "      <td>0.418107</td>\n",
       "      <td>33163</td>\n",
       "      <td>0.507351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.474685</td>\n",
       "      <td>0.600806</td>\n",
       "      <td>25119</td>\n",
       "      <td>13455</td>\n",
       "      <td>0.535650</td>\n",
       "      <td>22661</td>\n",
       "      <td>0.346684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.600819</td>\n",
       "      <td>0.972367</td>\n",
       "      <td>12560</td>\n",
       "      <td>9206</td>\n",
       "      <td>0.732962</td>\n",
       "      <td>9206</td>\n",
       "      <td>0.140840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           min       max  Total  Fakes      Pred  fake_count    recall\n",
       "0.0   0.000486  0.067426  12559    417  0.033203       65365  1.000000\n",
       "1.0   0.067426  0.102547  25119   1535  0.061109       64948  0.993620\n",
       "2.0   0.102549  0.135340  25118   2301  0.091608       63413  0.970137\n",
       "3.0   0.135341  0.171576  25119   3197  0.127274       61112  0.934935\n",
       "4.0   0.171577  0.211524  25119   4204  0.167363       57915  0.886025\n",
       "5.0   0.211526  0.254184  25118   5427  0.216060       53711  0.821709\n",
       "6.0   0.254185  0.307527  25119   6670  0.265536       48284  0.738683\n",
       "7.0   0.307529  0.380506  25119   8451  0.336439       41614  0.636640\n",
       "8.0   0.380508  0.474683  25118  10502  0.418107       33163  0.507351\n",
       "9.0   0.474685  0.600806  25119  13455  0.535650       22661  0.346684\n",
       "10.0  0.600819  0.972367  12560   9206  0.732962        9206  0.140840"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "e:\\miniconda\\envs\\vir_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 53 columns):\n",
      "RETAILER_EL_NUMBER                1048575 non-null object\n",
      "REG_Q                             1048575 non-null int64\n",
      "MSISDN                            1048575 non-null int64\n",
      "TOT_MOB_REV_WK1                   1048575 non-null float64\n",
      "TOT_VC_REV_WK1                    1048575 non-null float64\n",
      "TOT_VC_OG_REV_WK1                 1048575 non-null float64\n",
      "TOT_VC_OG_MOU_WK1                 1048575 non-null float64\n",
      "TOT_VC_OG_COUNT_WK1               1048575 non-null float64\n",
      "TOT_VC_IC_MOU_WK1                 1048575 non-null float64\n",
      "TOT_VC_IC_COUNT_WK1               1048575 non-null float64\n",
      "TOT_VC_LCL_OG_REV_WK1             1048575 non-null float64\n",
      "TOT_VC_LCL_OG_MOU_WK1             1048575 non-null float64\n",
      "TOT_VC_LCL_OG_COUNT_WK1           1048575 non-null float64\n",
      "TOT_VC_LCL_ONNET_OG_REV_WK1       1048575 non-null float64\n",
      "TOT_VC_LCL_ONNET_OG_MOU_WK1       1048575 non-null float64\n",
      "TOT_VC_LCL_ONNET_OG_COUNT_WK1     1048575 non-null float64\n",
      "TOT_VC_LCL_OFFNET_OG_REV_WK1      1048575 non-null float64\n",
      "TOT_VC_LCL_OFFNET_OG_MOU_WK1      1048575 non-null float64\n",
      "TOT_VC_LCL_OFFNET_OG_COUNT_WK1    1048575 non-null float64\n",
      "TOT_VC_CHARGEABLE_MOU_WK1         1048575 non-null float64\n",
      "TOT_VC_CHARGEABLE_COUNT_WK1       1048575 non-null float64\n",
      "TOT_VC_BONUS_MOU_WK1              1048575 non-null float64\n",
      "TOT_VC_BONUS_COUNT_WK1            1048575 non-null float64\n",
      "TOT_VC_BUNDLE_REV_WK1             1048575 non-null float64\n",
      "TOT_VC_RC_REV_WK1                 1048575 non-null float64\n",
      "TOT_VC_RC_MOU_WK1                 1048575 non-null float64\n",
      "TOT_VC_RC_COUNT_WK1               1048575 non-null float64\n",
      "TOT_VC_ONNET_INC_COUNT_WK1        1048575 non-null float64\n",
      "TOT_VC_OFFNET_INC_MOU_WK1         1048575 non-null float64\n",
      "TOT_VC_OFFNET_INC_COUNT_WK1       1048575 non-null float64\n",
      "TOT_DATA_VOL_WK1                  1048575 non-null float64\n",
      "TOT_DATA_PPU_VOL_WK1              1048575 non-null float64\n",
      "TOT_DATA_BUNDLE_VOL_WK1           1048575 non-null float64\n",
      "TOT_DATA_BONUS_VOL_WK1            1048575 non-null float64\n",
      "DATA_BUNDLE_2G_VOL_WK1            1048575 non-null float64\n",
      "DATA_BUNDLE_3G_VOL_WK1            1048575 non-null float64\n",
      "DATA_BUNDLE_4G_VOL_WK1            1048575 non-null float64\n",
      "DATA_BONUS_2G_VOL_WK1             1048575 non-null float64\n",
      "DATA_BONUS_3G_VOL_WK1             1048575 non-null float64\n",
      "DATA_BONUS_4G_VOL_WK1             1048575 non-null float64\n",
      "DATA_EL_VOL_WK1                   1048575 non-null float64\n",
      "DATA_USSD_VOL_WK1                 1048575 non-null float64\n",
      "DATA_OTHER_VOL_WK1                1048575 non-null float64\n",
      "TOTAL_REFILL_COUNT_WK1            1048575 non-null float64\n",
      "TOTAL_REFILL_AMOUNT_WK1           1048575 non-null float64\n",
      "TOTAL_EL_REFILL_COUNT_WK1         1048575 non-null float64\n",
      "TOTAL_EL_REFILL_AMOUNT_WK1        1048575 non-null float64\n",
      "RGB_DAY_W1                        1048575 non-null int64\n",
      "DATA_DOU_DAY_W1                   1048575 non-null int64\n",
      "REFILL_DAY_W1                     1048575 non-null int64\n",
      "FAKE                              1048575 non-null int64\n",
      "LTE                               1048575 non-null object\n",
      "DEVICE_CAT                        1048575 non-null int64\n",
      "dtypes: float64(44), int64(7), object(2)\n",
      "memory usage: 424.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = []\n",
    "for values in df.columns:\n",
    "    cat_features.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_ohe_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f6f66ab0ee80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     categorical_names[X_train.columns.get_loc(col)] = [new_col.split(\"__\")[1] \n\u001b[1;32m----> 4\u001b[1;33m                                                        \u001b[1;32mfor\u001b[0m \u001b[0mnew_col\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_ohe_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                                                        if new_col.split(\"__\")[0] == col]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_ohe_features' is not defined"
     ]
    }
   ],
   "source": [
    "categorical_names = {}\n",
    "for col in cat_features:\n",
    "    categorical_names[X_train.columns.get_loc(col)] = [new_col.split(\"__\")[1] \n",
    "                                                       for new_col in new_ohe_features \n",
    "                                                       if new_col.split(\"__\")[0] == col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'named_transformers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-08dba647632a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mohe_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"categorical\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'named_transformers_'"
     ]
    }
   ],
   "source": [
    "ohe_categories = model.named_transformers_[\"categorical\"].categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REG_Q',\n",
       " 'TOT_MOB_REV_WK1',\n",
       " 'TOT_VC_REV_WK1',\n",
       " 'TOT_VC_OG_REV_WK1',\n",
       " 'TOT_VC_OG_MOU_WK1',\n",
       " 'TOT_VC_OG_COUNT_WK1',\n",
       " 'TOT_VC_IC_MOU_WK1',\n",
       " 'TOT_VC_IC_COUNT_WK1',\n",
       " 'TOT_VC_LCL_OG_REV_WK1',\n",
       " 'TOT_VC_LCL_OG_MOU_WK1',\n",
       " 'TOT_VC_LCL_OG_COUNT_WK1',\n",
       " 'TOT_VC_LCL_ONNET_OG_REV_WK1',\n",
       " 'TOT_VC_LCL_ONNET_OG_MOU_WK1',\n",
       " 'TOT_VC_LCL_ONNET_OG_COUNT_WK1',\n",
       " 'TOT_VC_LCL_OFFNET_OG_REV_WK1',\n",
       " 'TOT_VC_LCL_OFFNET_OG_MOU_WK1',\n",
       " 'TOT_VC_LCL_OFFNET_OG_COUNT_WK1',\n",
       " 'TOT_VC_CHARGEABLE_MOU_WK1',\n",
       " 'TOT_VC_CHARGEABLE_COUNT_WK1',\n",
       " 'TOT_VC_BONUS_MOU_WK1',\n",
       " 'TOT_VC_BONUS_COUNT_WK1',\n",
       " 'TOT_VC_BUNDLE_REV_WK1',\n",
       " 'TOT_VC_RC_REV_WK1',\n",
       " 'TOT_VC_RC_MOU_WK1',\n",
       " 'TOT_VC_RC_COUNT_WK1',\n",
       " 'TOT_VC_ONNET_INC_COUNT_WK1',\n",
       " 'TOT_VC_OFFNET_INC_MOU_WK1',\n",
       " 'TOT_VC_OFFNET_INC_COUNT_WK1',\n",
       " 'TOT_DATA_VOL_WK1',\n",
       " 'TOT_DATA_PPU_VOL_WK1',\n",
       " 'TOT_DATA_BUNDLE_VOL_WK1',\n",
       " 'TOT_DATA_BONUS_VOL_WK1',\n",
       " 'DATA_BUNDLE_2G_VOL_WK1',\n",
       " 'DATA_BUNDLE_3G_VOL_WK1',\n",
       " 'DATA_BUNDLE_4G_VOL_WK1',\n",
       " 'DATA_BONUS_2G_VOL_WK1',\n",
       " 'DATA_BONUS_3G_VOL_WK1',\n",
       " 'DATA_BONUS_4G_VOL_WK1',\n",
       " 'DATA_EL_VOL_WK1',\n",
       " 'DATA_USSD_VOL_WK1',\n",
       " 'DATA_OTHER_VOL_WK1',\n",
       " 'TOTAL_REFILL_COUNT_WK1',\n",
       " 'TOTAL_REFILL_AMOUNT_WK1',\n",
       " 'TOTAL_EL_REFILL_COUNT_WK1',\n",
       " 'TOTAL_EL_REFILL_AMOUNT_WK1',\n",
       " 'RGB_DAY_W1',\n",
       " 'DATA_DOU_DAY_W1',\n",
       " 'REFILL_DAY_W1',\n",
       " 'LTE',\n",
       " 'DEVICE_CAT']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
